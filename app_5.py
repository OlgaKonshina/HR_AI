import streamlit as st
import openai
import time
import json
import os
import PyPDF2
import docx
import pandas as pd
from io import BytesIO
import re
import uuid
from datetime import datetime
import requests
from pathlib import Path
import sys
import torch
import torch.nn.functional as F

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="HR –ë–æ—Ç - AI Recruiter",
    page_icon="üéØ",
    layout="wide"
)
def get_query_params():
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ query parameters"""
    import streamlit as st
    if hasattr(st, 'query_params'):
        return st.query_params
    else:
        return st.experimental_get_query_params()

# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–∞–∫:
query_params = get_query_params()
is_candidate = 'interview_id' in query_params

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(str(Path(__file__).parent))

try:
    from audio_text import text_to_ogg, recognize_audio_whisper
    from audio_recording import load_audio
    from config import DEEPSEEK_API_KEY
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –≤–µ–±-–≤–µ—Ä—Å–∏–∏
    def text_to_ogg(*args, **kwargs):
        return True


    def recognize_audio_whisper(*args, **kwargs):
        return "–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç"


    def load_audio(*args, **kwargs):
        return "test_audio.ogg"


    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', 'test-key')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤–µ–±-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
BASE_URL = os.getenv('BASE_URL', 'http://localhost:8501')
IS_PRODUCTION = os.getenv('IS_PRODUCTION', 'False').lower() == 'true'

# –ú–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö embeddings
RU_BERT_MODEL = "cointegrated/rubert-tiny2"

# –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
INTERVIEWS_DB = "interviews_db.json"


class InterviewDB:
    """–ü—Ä–æ—Å—Ç–∞—è JSON –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é"""

    def __init__(self, db_file=INTERVIEWS_DB):
        self.db_file = db_file
        self._ensure_db_exists()

    def _ensure_db_exists(self):
        if not Path(self.db_file).exists():
            with open(self.db_file, 'w', encoding='utf-8') as f:
                json.dump({}, f)

    def save_interview(self, interview_id, data):
        with open(self.db_file, 'r', encoding='utf-8') as f:
            db = json.load(f)
        db[interview_id] = data
        with open(self.db_file, 'w', encoding='utf-8') as f:
            json.dump(db, f, ensure_ascii=False, indent=2)

    def get_interview(self, interview_id):
        with open(self.db_file, 'r', encoding='utf-8') as f:
            db = json.load(f)
        return db.get(interview_id)


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
interview_db = InterviewDB()


class InterviewBot:
    def __init__(self, api_key, job_description, resume):
        self.client = openai.OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
        self.job_description = job_description
        self.resume = resume
        self.questions = []
        self.answers = []
        self.feedbacks = []

    def _format_qa_for_assessment(self):  # –î–û–ë–ê–í–õ–ï–ù–û
        formatted = ""
        for i, (question, answer, feedback) in enumerate(zip(self.questions, self.answers, self.feedbacks), 1):
            formatted += f"{i}. –í: {question}\n   –û: {answer}\n   –§: {feedback}\n\n"
        return formatted

    def generate_question(self, previous_answer=None):
        if previous_answer is None:
            prompt = '–ù–∞—á–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –æ –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.'
        else:
            prompt = f'–û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {previous_answer}. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ª–æ–≥–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å.'

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system",
                 "content": f'–¢—ã HR-–∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –¢–µ–±—è –∑–æ–≤—É—Ç –õ–µ–≤. –í–∞–∫–∞–Ω—Å–∏—è: {self.job_description}. –†–µ–∑—é–º–µ: {self.resume}. –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏.–ó–∞–¥–∞–≤–∞–π –Ω–∞–≤–æ–¥—è—â–∏–µ –∏ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã'},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    def provide_feedback(self, question, answer):
        """–î–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ –æ—Ç–≤–µ—Ç—É –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        feedback_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è.

        –í–ê–ö–ê–ù–°–ò–Ø: {self.job_description}
        –í–û–ü–†–û–°: {question}
        –û–¢–í–ï–¢ –ö–ê–ù–î–ò–î–ê–¢–ê: {answer}

        –î–∞–π –∫—Ä–∞—Ç–∫—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):
        - –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ—Ç–≤–µ—Ç–∞
        - –ß—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –±—É–¥—É—â–∏—Ö —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π
        """

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system",
                 "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç. –î–∞–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ –æ—Ç–≤–µ—Ç–∞–º –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏."},
                {"role": "user", "content": feedback_prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    def generate_final_report(self, email):
        assessment_prompt = f"""
        –ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –¥–∞–π –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.

        –í–ê–ö–ê–ù–°–ò–Ø: {self.job_description}
        –†–ï–ó–Æ–ú–ï –ö–ê–ù–î–ò–î–ê–¢–ê: {self.resume}
        –í–û–ü–†–û–°–´ –ò –û–¢–í–ï–¢–´: {self._format_qa_for_assessment()}

        –°–¥–µ–ª–∞–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É:
        1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ 
        3. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç
        4. –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        5. –ó–æ–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è
        6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ –Ω–∞–π–º—É (–¥–∞/–Ω–µ—Ç)
        7. –û–±—â–∏–π –±–∞–ª–ª –æ—Ç 1 –¥–æ 10

        –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å –∫–æ–Ω—Ç–∞–∫—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {email}
        """

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "–¢—ã —Å—Ç–∞—Ä—à–∏–π HR-–º–µ–Ω–µ–¥–∂–µ—Ä. –î–∞–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞."},
                {"role": "user", "content": assessment_prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    @staticmethod
    def get_embedding(text, model_path=RU_BERT_MODEL):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç embedding —Å –ø–æ–º–æ—â—å—é RuBERT-Tiny"""
        try:
            from transformers import AutoTokenizer, AutoModel

            # –ö—ç—à–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä
            if not hasattr(InterviewBot, '_tokenizer'):
                InterviewBot._tokenizer = AutoTokenizer.from_pretrained(model_path)
            if not hasattr(InterviewBot, '_model'):
                InterviewBot._model = AutoModel.from_pretrained(model_path)

            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = InterviewBot._tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            )

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            with torch.no_grad():
                outputs = InterviewBot._model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
                embeddings = F.normalize(embeddings, p=2, dim=1)

            return embeddings

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è embedding: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π embedding –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return torch.randn(1, 312)  # –†–∞–∑–º–µ—Ä –¥–ª—è rubert-tiny

    @staticmethod
    def filter_resumes_with_rubert(resumes, job_description):
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RuBERT-Tiny"""
        filtered = []

        try:
            # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏
            job_emb = InterviewBot.get_embedding(job_description[:512])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

            for i, resume in enumerate(resumes):
                with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ {i + 1}/{len(resumes)} —Å –ø–æ–º–æ—â—å—é RuBERT-Tiny..."):
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è —Ä–µ–∑—é–º–µ
                        resume_short = resume['text'][:1000]  # –ë–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ —Ä–µ–∑—é–º–µ
                        resume_emb = InterviewBot.get_embedding(resume_short)

                        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                        similarity = F.cosine_similarity(job_emb, resume_emb).item() * 100

                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        analysis_result = InterviewBot._analyze_rubert_result(
                            similarity, resume['text'], job_description
                        )

                        resume['analysis'] = analysis_result

                        if analysis_result['is_suitable']:
                            filtered.append(resume)

                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ {resume['name']}: {str(e)}")
                        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                        analysis_result = InterviewBot._analyze_resume_fallback(
                            resume['text'], job_description
                        )
                        resume['analysis'] = analysis_result
                        if analysis_result['is_suitable']:
                            filtered.append(resume)

            return sorted(filtered, key=lambda x: x['analysis']['match_score'], reverse=True)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å RuBERT: {str(e)}")
            return InterviewBot.filter_resumes_fallback(resumes, job_description)

    @staticmethod
    def _analyze_rubert_result(similarity, resume_text, job_description):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ RuBERT"""
        is_suitable = similarity >= 40

        strengths = []
        weaknesses = []

        if similarity >= 60:
            strengths.append("–í—ã—Å–æ–∫–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        elif similarity >= 40:
            strengths.append("–£–º–µ—Ä–µ–Ω–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        else:
            weaknesses.append("–ù–∏–∑–∫–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        resume_lower = resume_text.lower()
        job_lower = job_description.lower()

        # –ò—â–µ–º –æ–±—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        resume_words = set(re.findall(r'\b[–∞-—è–ê-–Ø]{4,}\b', resume_lower))
        job_words = set(re.findall(r'\b[–∞-—è–ê-–Ø]{4,}\b', job_lower))
        common_words = resume_words.intersection(job_words)

        if common_words:
            strengths.append(f"–û–±—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(list(common_words)[:5])}")

        return {
            'match_score': round(similarity, 1),
            'is_suitable': is_suitable,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'reason': f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ (RuBERT): {similarity:.1f}%"
        }

    @staticmethod
    def _analyze_resume_fallback(resume_text, job_description):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö RuBERT"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö
        stop_words = {'–æ–ø—ã—Ç', '—Ä–∞–±–æ—Ç–∞', '—Ä–∞–±–æ—Ç—ã', '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–∑–Ω–∞–Ω–∏–µ', '–Ω–∞–≤—ã–∫–∏'}
        job_words = re.findall(r'\b[–∞-—è–ê-–Ø]{4,}\b', job_description.lower())
        job_keywords = [word for word in job_words if word not in stop_words]

        from collections import Counter
        job_keywords = [word for word, count in Counter(job_keywords).most_common(10)]

        resume_lower = resume_text.lower()
        score = 0
        found_keywords = []

        for keyword in job_keywords:
            if keyword in resume_lower:
                score += 10
                found_keywords.append(keyword)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø—ã—Ç–∞
        if re.search(r'–æ–ø—ã—Ç.*?\d+.*?(–≥–æ–¥|–ª–µ—Ç)', resume_lower):
            score += 30

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        if any(edu in resume_lower for edu in ['–≤—ã—Å—à–µ–µ', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '–≤—É–∑']):
            score += 20

        analysis_result = {
            'match_score': min(score, 100),
            'is_suitable': score >= 40,
            'strengths': [],
            'weaknesses': [],
            'reason': f"–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {score}%"
        }

        if found_keywords:
            analysis_result['strengths'].append(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(found_keywords[:3])}")

        if score < 40:
            analysis_result['weaknesses'].append("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")

        return analysis_result


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
def extract_text_from_file(file):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    try:
        if file.type == "application/pdf":
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text

        elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = docx.Document(BytesIO(file.read()))
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text

        elif file.type == "text/plain":
            return file.read().decode("utf-8", errors='ignore')

        else:
            return f"–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ {file.name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file.name}: {str(e)}"


def create_interview_link(candidate_data, job_description, hr_email):
    """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"""
    interview_id = str(uuid.uuid4())[:8]

    interview_data = {
        'candidate': candidate_data,
        'job_description': job_description,
        'hr_email': hr_email,
        'created_at': datetime.now().strftime("%Y-%m-%d %H:%M"),
        'status': 'pending'
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    interview_db.save_interview(interview_id, interview_data)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ä–µ–¥—ã
    if IS_PRODUCTION:
        # –í production –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π URL
        return f"{BASE_URL}/?interview_id={interview_id}"
    else:
        # –í development - localhost
        return f"http://localhost:8501/?interview_id={interview_id}"


# –û–°–ù–û–í–ù–û–ô –ö–û–î
query_params = st.query_params
is_candidate = 'interview_id' in query_params

if is_candidate:
    # üë§ –†–ï–ñ–ò–ú –°–û–ò–°–ö–ê–¢–ï–õ–Ø
    interview_id = query_params['interview_id'][0]
    interview_data = interview_db.get_interview(interview_id)

    if interview_data:
        candidate = interview_data['candidate']
        job_description = interview_data['job_description']
        hr_email = interview_data['hr_email']

        st.title("üé§ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ")
        st.write("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –æ–Ω–ª–∞–π–Ω-—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ!")

        st.info(f"**–í–∞–∫–∞–Ω—Å–∏—è:** {job_description[:100]}...")
        st.info(f"**–ö–æ–Ω—Ç–∞–∫—Ç HR:** {hr_email}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if 'interview_bot' not in st.session_state:
            st.session_state.interview_bot = InterviewBot(
                DEEPSEEK_API_KEY,
                job_description,
                candidate['text']
            )
            st.session_state.current_question = 0
            st.session_state.questions = []
            st.session_state.answers = []

        bot = st.session_state.interview_bot

        # –ü—Ä–æ—Ü–µ—Å—Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if st.session_state.current_question < 3:
            if st.session_state.current_question >= len(st.session_state.questions):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
                previous_answer = st.session_state.answers[-1] if st.session_state.answers else None
                question = bot.generate_question(previous_answer)
                st.session_state.questions.append(question)
                st.session_state.answers.append("")

            st.subheader(f"–í–æ–ø—Ä–æ—Å {st.session_state.current_question + 1}/3")
            st.info(st.session_state.questions[st.session_state.current_question])

            # –ó–∞–ø–∏—Å—å –æ—Ç–≤–µ—Ç–∞
            if st.button("üé§ –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç", key=f"record_{st.session_state.current_question}"):
                with st.spinner("–ó–∞–ø–∏—Å—å... (15 —Å–µ–∫—É–Ω–¥)"):
                    audio_file = load_audio(duration=15)
                    answer = recognize_audio_whisper(audio_file)
                    st.session_state.answers[st.session_state.current_question] = answer

                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
                    feedback = bot.provide_feedback(
                        st.session_state.questions[st.session_state.current_question],
                        answer
                    )
                    bot.feedbacks.append(feedback)

                    st.session_state.current_question += 1
                    st.rerun()

            if st.session_state.answers[st.session_state.current_question]:
                st.write("**–í–∞—à –æ—Ç–≤–µ—Ç:**")
                st.write(st.session_state.answers[st.session_state.current_question])

        else:
            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
            st.success("‚úÖ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.balloons()

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –¥–ª—è HR..."):
                final_report = bot.generate_final_report(hr_email)
                interview_data['report'] = final_report
                interview_data['status'] = 'completed'

                # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
                interview_db.save_interview(interview_id, interview_data)

                st.subheader("üìã –û—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω HR")
                st.write(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ email: **{hr_email}**")
                st.write("–° –≤–∞–º–∏ —Å–≤—è–∂—É—Ç—Å—è –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è!")

    else:
        st.error("‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ")
        st.write("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ HR")

else:
    # üëî –†–ï–ñ–ò–ú HR-–°–ü–ï–¶–ò–ê–õ–ò–°–¢–ê
    st.title("üéØ AI Recruiter - –ü–∞–Ω–µ–ª—å HR")

    tab1, tab2 = st.tabs(["üìÅ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞", "üë• –≠—Ç–∞–ø 2: –û—Ç–±–æ—Ä"])

    with tab1:
        st.header("üìÅ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("–î–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
            job_file = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏:",
                type=["pdf", "docx", "txt"],
                key="job_file"
            )

            if job_file:
                job_text = extract_text_from_file(job_file)
                st.session_state.job_description = job_text
                st.success("‚úÖ –í–∞–∫–∞–Ω—Å–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                st.text_area("–ü—Ä–µ–≤—å—é:", job_text[:500] + "...", height=150)

            st.session_state.hr_email = st.text_input("üìß –í–∞—à email:")

        with col2:
            st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ")
            uploaded_files = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ (–¥–æ 100 —Ñ–∞–π–ª–æ–≤):",
                type=["pdf", "docx", "txt"],
                accept_multiple_files=True,
                key="resume_files"
            )

            if uploaded_files:
                st.session_state.resumes = []
                for file in uploaded_files:
                    text = extract_text_from_file(file)
                    st.session_state.resumes.append({
                        'name': file.name,
                        'text': text,
                        'type': file.type
                    })
                st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_files)} —Ä–µ–∑—é–º–µ")

        if st.button("üöÄ –ù–∞—á–∞—Ç—å AI-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é",
                     type="primary") and st.session_state.job_description and st.session_state.hr_email and st.session_state.resumes:
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ —Å –ø–æ–º–æ—â—å—é RuBERT-Tiny..."):
                st.session_state.filtered_candidates = InterviewBot.filter_resumes_with_rubert(
                    st.session_state.resumes, st.session_state.job_description
                )
            st.success(f"RuBERT-Tiny –æ—Ç–æ–±—Ä–∞–ª {len(st.session_state.filtered_candidates)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")

    with tab2:
        st.header("üë• –≠—Ç–∞–ø 2: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–±–æ—Ä–∞")

        if not st.session_state.get('filtered_candidates'):
            st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
        else:
            st.write(f"**–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:** {len(st.session_state.filtered_candidates)}")

            for i, candidate in enumerate(st.session_state.filtered_candidates):
                analysis = candidate.get('analysis', {})

                with st.expander(f"–ö–∞–Ω–¥–∏–¥–∞—Ç {i + 1}: {candidate['name']} (Score: {analysis.get('match_score', 0)}%)"):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**üìä –ê–Ω–∞–ª–∏–∑:**")
                        st.write(f"**–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ:** {analysis.get('match_score', 0)}%")
                        st.write(
                            f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {'‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç' if analysis.get('is_suitable', False) else '‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç'}")

                        st.write("**‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
                        for strength in analysis.get('strengths', []):
                            st.write(f"‚Ä¢ {strength}")

                    with col2:
                        st.write("**‚ùå –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
                        for weakness in analysis.get('weaknesses', []):
                            st.write(f"‚Ä¢ {weakness}")

                        st.write("**üìù –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**")
                        st.write(analysis.get('reason', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'))

                        if st.button(f"üìß –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ", key=f"invite_{i}"):
                            interview_link = create_interview_link(
                                candidate, st.session_state.job_description, st.session_state.hr_email
                            )

                            st.success("‚úÖ –°—Å—ã–ª–∫–∞ —Å–æ–∑–¥–∞–Ω–∞!")
                            st.text_area("–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Å—ã–ª–∫—É –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:", interview_link)

# –§—É—Ç–µ—Ä
st.write("---")
st.caption(f"HR AI Recruiter v1.0 | RuBERT-Tiny | {'Production' if IS_PRODUCTION else 'Development'}")

# –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
if not IS_PRODUCTION:
    st.sidebar.write("üîß –û—Ç–ª–∞–¥–∫–∞")
    if st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É –∏–Ω—Ç–µ—Ä–≤—å—é"):
        interview_db._ensure_db_exists()
        st.sidebar.success("–ë–∞–∑–∞ –æ—á–∏—â–µ–Ω–∞")