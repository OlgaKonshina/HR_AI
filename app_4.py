import streamlit as st
import openai
import os
import PyPDF2
import docx
from io import BytesIO
import re
import uuid
from datetime import datetime
from audio_text import text_to_ogg, recognize_audio_whisper
from audio_recording import load_audio
from config import DEEPSEEK_API_KEY
import sys
from pathlib import Path

import json
import re
from pathlib import Path
import pandas as pd
import docx
from striprtf.striprtf import rtf_to_text
import fitz  # PyMuPDF
from transformers import AutoTokenizer, AutoModel
import torch
import torch.nn.functional as F

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ document_processor
sys.path.append(str(Path(__file__).parent))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
# –ò–∑–º–µ–Ω–∏—Ç–µ –∏–º–ø–æ—Ä—Ç –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ app_streamlit.py
try:
    from document_processor import DocumentReader, extract_job_title

    # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å get_embedding —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏
    try:
        from document_processor import get_embedding

        print("‚úÖ get_embedding –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å
            test_embedding = get_embedding("—Ç–µ—Å—Ç", "cointegrated/rubert-tiny2")
            print("‚úÖ RuBERT-Tiny –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            DOCUMENT_PROCESSOR_AVAILABLE = True
        except Exception as e:
            print(f"‚ö†Ô∏è RuBERT-Tiny –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å
            try:
                test_embedding = get_embedding("—Ç–µ—Å—Ç", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
                print("‚úÖ Multilingual –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                DOCUMENT_PROCESSOR_AVAILABLE = True
            except Exception as e2:
                print(f"‚ùå –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç: {e2}")
                DOCUMENT_PROCESSOR_AVAILABLE = False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ get_embedding: {e}")
        DOCUMENT_PROCESSOR_AVAILABLE = False

except ImportError as e:
    print(f"‚ùå –û—Å–Ω–æ–≤–Ω–æ–π –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è: {e}")
    DOCUMENT_PROCESSOR_AVAILABLE = False


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
try:
    from striprtf.striprtf import rtf_to_text
except ImportError:
    st.error("–î–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ RTF —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: !pip install striprtf")
try:
    import odfpy
    from odf import text, teletype
except ImportError:
    st.error("–î–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ ODT —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: !pip install odfpy")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="HR –ë–æ—Ç - AI Recruiter",
    page_icon="üéØ",
    layout="wide"
)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
if 'interviews' not in st.session_state:
    st.session_state.interviews = {}
if 'job_description' not in st.session_state:
    st.session_state.job_description = ""
if 'hr_email' not in st.session_state:
    st.session_state.hr_email = ""
if 'resumes' not in st.session_state:
    st.session_state.resumes = []
if 'filtered_candidates' not in st.session_state:
    st.session_state.filtered_candidates = []


class InterviewBot:
    def __init__(self, api_key, job_description, resume):
        self.client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com/v1")
        self.job_description = job_description
        self.resume = resume
        self.questions = []
        self.answers = []
        self.feedbacks = []

    def generate_question(self, previous_answer=None):
        if previous_answer is None:
            prompt = '–ù–∞—á–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –æ –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.'
        else:
            prompt = f'–û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {previous_answer}. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ª–æ–≥–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å.'

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system",
                 "content": f'–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –í–∞–∫–∞–Ω—Å–∏—è: {self.job_description}. –†–µ–∑—é–º–µ: {self.resume}. –ó–∞–¥–∞–≤–∞–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏.'},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    def provide_feedback(self, question, answer):
        feedback_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å.

        –í–ê–ö–ê–ù–°–ò–Ø: {self.job_description}
        –í–û–ü–†–û–°: {question}
        –û–¢–í–ï–¢ –ö–ê–ù–î–ò–î–ê–¢–ê: {answer}

        –î–∞–π –∫—Ä–∞—Ç–∫—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å:
        - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≥–ª—É–±–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç
        - –ß—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        """

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –î–∞–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å."},
                {"role": "user", "content": feedback_prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    def generate_final_report(self, email):
        assessment_prompt = f"""
        –ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –¥–∞–π –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.

        –í–ê–ö–ê–ù–°–ò–Ø: {self.job_description}
        –†–ï–ó–Æ–ú–ï –ö–ê–ù–î–ò–î–ê–¢–ê: {self.resume}
        –í–û–ü–†–û–°–´ –ò –û–¢–í–ï–¢–´: {self._format_qa_for_assessment()}

        –°–¥–µ–ª–∞–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É:
        - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ 
        - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç
        - –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        - –ó–æ–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ –Ω–∞–π–º—É (–¥–∞/–Ω–µ—Ç)
        - –û–±—â–∏–π –±–∞–ª–ª –æ—Ç 1 –¥–æ 10

        –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å –∫–æ–Ω—Ç–∞–∫—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {email}
        """

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "–¢—ã —Å—Ç–∞—Ä—à–∏–π HR-–º–µ–Ω–µ–¥–∂–µ—Ä. –î–∞–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞."},
                {"role": "user", "content": assessment_prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content

    def _format_qa_for_assessment(self):
        formatted = ""
        for i, (question, answer, feedback) in enumerate(zip(self.questions, self.answers, self.feedbacks), 1):
            formatted += f"{i}. –í: {question}\n   –û: {answer}\n   –§: {feedback}\n\n"
        return formatted

    @staticmethod
    def filter_resumes_with_embeddings(resumes, job_description):
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º embeddings –∏–∑ document_processor"""
        if not DOCUMENT_PROCESSOR_AVAILABLE:
            st.error("–ú–æ–¥—É–ª—å document_processor –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥.")
            return InterviewBot.filter_resumes_fallback(resumes, job_description)

        filtered = []
        model_path = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

        try:
            # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏
            job_emb = get_embedding(job_description, model_path)

            for i, resume in enumerate(resumes):
                with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ {i + 1}/{len(resumes)} —Å –ø–æ–º–æ—â—å—é embeddings..."):
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è —Ä–µ–∑—é–º–µ
                        resume_emb = get_embedding(resume['text'], model_path)

                        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                        similarity = torch.mm(resume_emb, job_emb.T).item() * 100

                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        analysis_result = InterviewBot._analyze_embedding_result(similarity, resume['text'],
                                                                                 job_description)

                        resume['analysis'] = analysis_result

                        if analysis_result['is_suitable']:
                            filtered.append(resume)

                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ {resume['name']} —Å embeddings: {str(e)}")
                        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                        analysis_result = InterviewBot._analyze_resume_fallback(resume['text'], job_description)
                        resume['analysis'] = analysis_result
                        if analysis_result['is_suitable']:
                            filtered.append(resume)

            return sorted(filtered, key=lambda x: x['analysis']['match_score'], reverse=True)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å embeddings: {str(e)}")
            return InterviewBot.filter_resumes_fallback(resumes, job_description)

    @staticmethod
    def filter_resumes_with_embeddings(resumes, job_description):
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö embeddings"""
        if not DOCUMENT_PROCESSOR_AVAILABLE:
            st.error("–ú–æ–¥—É–ª—å document_processor –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥.")
            return InterviewBot.filter_resumes_fallback(resumes, job_description)

        filtered = []

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å
        model_path = "cointegrated/rubert-tiny2"  # –†—É—Å—Å–∫–∞—è –º–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å

        try:
            # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏
            job_emb = get_embedding(job_description[:512], model_path)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

            for i, resume in enumerate(resumes):
                with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ {i + 1}/{len(resumes)} —Å –ø–æ–º–æ—â—å—é RuBERT..."):
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è —Ä–µ–∑—é–º–µ (–ø–µ—Ä–≤—ã–µ 512 —Ç–æ–∫–µ–Ω–æ–≤)
                        resume_short = resume['text'][:1000]  # –ë–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ —Ä–µ–∑—é–º–µ
                        resume_emb = get_embedding(resume_short, model_path)

                        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                        similarity = torch.nn.functional.cosine_similarity(job_emb, resume_emb).item() * 100

                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        analysis_result = InterviewBot._analyze_embedding_result(similarity, resume['text'],
                                                                                 job_description)

                        resume['analysis'] = analysis_result

                        if analysis_result['is_suitable']:
                            filtered.append(resume)

                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ {resume['name']}: {str(e)}")
                        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                        analysis_result = InterviewBot._analyze_resume_fallback(resume['text'], job_description)
                        resume['analysis'] = analysis_result
                        if analysis_result['is_suitable']:
                            filtered.append(resume)

            return sorted(filtered, key=lambda x: x['analysis']['match_score'], reverse=True)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–º–∏ embeddings: {str(e)}")
            return InterviewBot.filter_resumes_fallback(resumes, job_description)

    @staticmethod
    def filter_resumes_fallback(resumes, job_description):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –±–µ–∑ embeddings"""
        filtered = []

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
        job_keywords = InterviewBot._extract_keywords(job_description)

        st.write(f"üîë **–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤–∞–∫–∞–Ω—Å–∏–∏:** {', '.join(job_keywords[:10])}")

        for i, resume in enumerate(resumes):
            with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ {i + 1}/{len(resumes)} (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥)..."):
                analysis_result = InterviewBot._analyze_resume_fallback(resume['text'], job_description, job_keywords)
                resume['analysis'] = analysis_result

                if analysis_result['is_suitable']:
                    filtered.append(resume)

        return sorted(filtered, key=lambda x: x['analysis']['match_score'], reverse=True)

    @staticmethod
    def _extract_keywords(text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        stop_words = {'–æ–ø—ã—Ç', '—Ä–∞–±–æ—Ç–∞', '—Ä–∞–±–æ—Ç—ã', '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–∑–Ω–∞–Ω–∏–µ', '–Ω–∞–≤—ã–∫–∏'}
        words = re.findall(r'\b[a-zA-Z–∞-—è–ê-–Ø]{4,}\b', text.lower())
        keywords = [word for word in words if word not in stop_words]

        from collections import Counter
        keyword_counts = Counter(keywords)
        return [word for word, count in keyword_counts.most_common(20)]

    @staticmethod
    def _analyze_resume_fallback(resume_text, job_description, job_keywords=None):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ"""
        if job_keywords is None:
            job_keywords = InterviewBot._extract_keywords(job_description)

        resume_lower = resume_text.lower()
        job_lower = job_description.lower()

        # –ü—Ä–æ—Å—Ç–æ–π scoring –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        score = 0
        found_keywords = []

        for keyword in job_keywords:
            if re.search(rf'\b{re.escape(keyword)}\b', resume_lower):
                score += 3
                found_keywords.append(keyword)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        experience_match = re.search(r'–æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã.*?(\d+)[^\d]*–ª–µ—Ç', resume_lower)
        if experience_match:
            years = int(experience_match.group(1))
            score += min(years * 2, 10)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º score
        max_score = len(job_keywords) * 3 + 10
        match_score = min(int((score / max_score) * 100), 100) if max_score > 0 else 0

        is_suitable = match_score >= 40

        strengths = []
        weaknesses = []

        if found_keywords:
            strengths.append(f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {', '.join(found_keywords[:5])}")

        if match_score < 40:
            weaknesses.append("–ù–∏–∑–∫–∏–π score —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è")

        return {
            'match_score': match_score,
            'is_suitable': is_suitable,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'reason': f"Score: {match_score}% - {'–ü–æ–¥—Ö–æ–¥–∏—Ç' if is_suitable else '–ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç'}"
        }


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
def extract_text_from_file(file):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DocumentReader –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –º–æ–¥—É–ª—è –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if DOCUMENT_PROCESSOR_AVAILABLE:
            try:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix=file.name) as tmp:
                    tmp.write(file.read())
                    tmp_path = tmp.name

                reader = DocumentReader(tmp_path)
                text = reader.extract_text()

                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                os.unlink(tmp_path)
                return text

            except Exception as e:
                st.warning(f"DocumentReader –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥.")

        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
        # PDF
        if file.type == "application/pdf":
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text

        # Word DOCX
        elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = docx.Document(BytesIO(file.read()))
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text

        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        elif file.type == "text/plain":
            return file.read().decode("utf-8", errors='ignore')

        else:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
            try:
                return file.read().decode("utf-8", errors='ignore')
            except:
                return f"–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ {file.name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file.name}: {str(e)}"


def create_interview_link(candidate_data, job_description, hr_email):
    """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"""
    interview_id = str(uuid.uuid4())[:8]

    st.session_state.interviews[interview_id] = {
        'candidate': candidate_data,
        'job_description': job_description,
        'hr_email': hr_email,
        'created_at': datetime.now().strftime("%Y-%m-%d %H:%M"),
        'status': 'pending'
    }

    return f"http://localhost:8501/?interview_id={interview_id}"


# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ query parameters
query_params = st.query_params
is_candidate = 'interview_id' in query_params

if is_candidate:
    # üë§ –†–ï–ñ–ò–ú –°–û–ò–°–ö–ê–¢–ï–õ–Ø - –≠–¢–ê–ü 3
    interview_id = query_params['interview_id'][0]

    if interview_id in st.session_state.interviews:
        interview_data = st.session_state.interviews[interview_id]
        candidate = interview_data['candidate']
        job_description = interview_data['job_description']
        hr_email = interview_data['hr_email']

        st.title("üé§ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ")
        st.write("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –æ–Ω–ª–∞–π–Ω-—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ!")

        st.info(f"**–í–∞–∫–∞–Ω—Å–∏—è:** {job_description[:100]}...")
        st.info(f"**–ö–æ–Ω—Ç–∞–∫—Ç HR:** {hr_email}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if 'interview_bot' not in st.session_state:
            st.session_state.interview_bot = InterviewBot(
                DEEPSEEK_API_KEY,
                job_description,
                candidate['text']
            )
            st.session_state.current_question = 0
            st.session_state.questions = []
            st.session_state.answers = []

        bot = st.session_state.interview_bot

        # –ü—Ä–æ—Ü–µ—Å—Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if st.session_state.current_question < 3:
            if st.session_state.current_question >= len(st.session_state.questions):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
                previous_answer = st.session_state.answers[-1] if st.session_state.answers else None
                question = bot.generate_question(previous_answer)
                st.session_state.questions.append(question)
                st.session_state.answers.append("")

            st.subheader(f"–í–æ–ø—Ä–æ—Å {st.session_state.current_question + 1}/3")
            st.info(st.session_state.questions[st.session_state.current_question])

            # –ó–∞–ø–∏—Å—å –æ—Ç–≤–µ—Ç–∞
            if st.button("üé§ –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç", key=f"record_{st.session_state.current_question}"):
                with st.spinner("–ó–∞–ø–∏—Å—å... (15 —Å–µ–∫—É–Ω–¥)"):
                    audio_file = load_audio(duration=15)
                    answer = recognize_audio_whisper(audio_file)
                    st.session_state.answers[st.session_state.current_question] = answer

                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
                    feedback = bot.provide_feedback(
                        st.session_state.questions[st.session_state.current_question],
                        answer
                    )
                    bot.feedbacks.append(feedback)

                    st.session_state.current_question += 1
                    st.rerun()

            if st.session_state.answers[st.session_state.current_question]:
                st.write("**–í–∞—à –æ—Ç–≤–µ—Ç:**")
                st.write(st.session_state.answers[st.session_state.current_question])

        else:
            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
            st.success("‚úÖ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.balloons()

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –¥–ª—è HR..."):
                final_report = bot.generate_final_report(hr_email)
                interview_data['report'] = final_report
                interview_data['status'] = 'completed'

                st.subheader("üìã –û—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω HR")
                st.write(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ email: **{hr_email}**")
                st.write("–° –≤–∞–º–∏ —Å–≤—è–∂—É—Ç—Å—è –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è!")

    else:
        st.error("‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ")
        st.write("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ HR")

else:
    # üëî –†–ï–ñ–ò–ú HR-–°–ü–ï–¶–ò–ê–õ–ò–°–¢–ê - –≠–¢–ê–ü–´ 1 –∏ 2
    st.title("üéØ AI Recruiter - –ü–∞–Ω–µ–ª—å HR")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    with st.sidebar:
        st.header("üìã –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã")
        st.write("""
        **–í–∞–∫–∞–Ω—Å–∏–∏ –∏ —Ä–µ–∑—é–º–µ:**
        - üìÑ PDF (.pdf)
        - üìù Word DOCX (.docx)
        - üìù Word DOC (.doc)
        - üìã RTF (.rtf)
        - üìò OpenDocument (.odt)
        - üì± –¢–µ–∫—Å—Ç (.txt)
        - üåê HTML (.html)
        """)

        if not DOCUMENT_PROCESSOR_AVAILABLE:
            st.warning("‚ö†Ô∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

    tab1, tab2 = st.tabs(["üìÅ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞", "üë• –≠—Ç–∞–ø 2: –û—Ç–±–æ—Ä"])

    with tab1:
        st.header("üìÅ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("–î–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
            job_file = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏:",
                type=["pdf", "docx", "txt", "rtf", "odt"],
                key="job_file"
            )

            if job_file:
                job_text = extract_text_from_file(job_file)
                st.session_state.job_description = job_text
                st.success("‚úÖ –í–∞–∫–∞–Ω—Å–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

                if job_text.startswith("–î–ª—è —á—Ç–µ–Ω–∏—è") or job_text.startswith("–û—à–∏–±–∫–∞"):
                    st.warning(job_text)
                else:
                    st.text_area("–ü—Ä–µ–≤—å—é –≤–∞–∫–∞–Ω—Å–∏–∏:", job_text[:500] + "..." if len(job_text) > 500 else job_text,
                                 height=150)

            st.session_state.hr_email = st.text_input("üìß –í–∞—à email –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏:")

        with col2:
            st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ")
            uploaded_files = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–æ 100 —Ñ–∞–π–ª–æ–≤):",
                type=["pdf", "docx", "txt", "rtf", "odt"],
                accept_multiple_files=True,
                key="resume_files"
            )

            if uploaded_files:
                if len(uploaded_files) > 100:
                    st.warning("–ú–∞–∫—Å–∏–º—É–º 100 —Ñ–∞–π–ª–æ–≤. –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 100.")
                    uploaded_files = uploaded_files[:100]

                st.session_state.resumes = []
                for file in uploaded_files:
                    text = extract_text_from_file(file)
                    st.session_state.resumes.append({
                        'name': file.name,
                        'text': text,
                        'type': file.type,
                        'size': file.size
                    })

                st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_files)} —Ä–µ–∑—é–º–µ")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º
                format_stats = {}
                for resume in st.session_state.resumes:
                    fmt = resume['name'].split('.')[-1].upper() if '.' in resume['name'] else 'OTHER'
                    format_stats[fmt] = format_stats.get(fmt, 0) + 1

                st.write("**üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤:**")
                for fmt, count in format_stats.items():
                    st.write(f"‚Ä¢ {fmt}: {count} —Ñ–∞–π–ª–æ–≤")

        # –ò–°–ü–û–õ–¨–ó–£–ï–ú –§–ò–õ–¨–¢–†–ê–¶–ò–Æ –ò–ó DOCUMENT_PROCESSOR
        if st.button("üöÄ –ù–∞—á–∞—Ç—å AI-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é",
                     type="primary") and st.session_state.job_description and st.session_state.hr_email and st.session_state.resumes:
            with st.spinner("AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—é–º–µ —Å –ø–æ–º–æ—â—å—é embeddings..."):
                st.session_state.filtered_candidates = InterviewBot.filter_resumes_with_embeddings(
                    st.session_state.resumes, st.session_state.job_description
                )
            st.success(f"AI –æ—Ç–æ–±—Ä–∞–ª {len(st.session_state.filtered_candidates)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")

    with tab2:
        st.header("üë• –≠—Ç–∞–ø 2: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AI-–æ—Ç–±–æ—Ä–∞")

        if not st.session_state.get('filtered_candidates'):
            st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ AI-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –≤ –≠—Ç–∞–ø–µ 1")
        else:
            st.write(f"**–ù–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:** {len(st.session_state.filtered_candidates)}")

            for i, candidate in enumerate(st.session_state.filtered_candidates):
                analysis = candidate.get('analysis', {})

                with st.expander(f"–ö–∞–Ω–¥–∏–¥–∞—Ç {i + 1}: {candidate['name']} (Score: {analysis.get('match_score', 0)}%)"):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**ü§ñ AI –ê–Ω–∞–ª–∏–∑:**")
                        st.write(f"**–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ:** {analysis.get('match_score', 0)}%")
                        st.write(
                            f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {'‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç' if analysis.get('is_suitable', False) else '‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç'}")

                        st.write("**‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
                        for strength in analysis.get('strengths', []):
                            st.write(f"‚Ä¢ {strength}")

                    with col2:
                        st.write("**‚ùå –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
                        for weakness in analysis.get('weaknesses', []):
                            st.write(f"‚Ä¢ {weakness}")

                        st.write("**üìù –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**")
                        st.write(analysis.get('reason', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'))

                        if st.button(f"üìß –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ", key=f"invite_{i}"):
                            interview_link = create_interview_link(
                                candidate, st.session_state.job_description, st.session_state.hr_email
                            )

                            st.success("‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∞!")
                            st.text_area("–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Å—ã–ª–∫—É –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:", interview_link)

                    st.write("**üìÑ –ü—Ä–µ–≤—å—é —Ä–µ–∑—é–º–µ:**")
                    st.text(candidate['text'][:300] + "..." if len(candidate['text']) > 300 else candidate['text'])

# –§—É—Ç–µ—Ä
st.write("---")
st.caption("AI Recruiter System v5.0 | –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä")