import streamlit as st
import torch
import time
from app import InterviewBot
from config import DEEPSEEK_API_KEY
from audio_recording import load_audio
from audio_text import recognize_audio_whisper, text_to_ogg
from document_processor import DocumentReader, extract_job_title, get_embedding, _generate_recommendation
from app import InterviewBot, print_interview_summary
# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
st.set_page_config(page_title="Interview Bot", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ===
st.header("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
job_file = st.file_uploader("–û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", type=["pdf", "docx", "rtf", "txt", "csv", "json"])
resume_file = st.file_uploader("–†–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞", type=["pdf", "docx", "rtf", "txt", "csv", "json"])

job_text, resume_text, similarity = None, None, None

if job_file and resume_file:
    job_path = f"uploaded_{job_file.name}"
    resume_path = f"uploaded_{resume_file.name}"
    with open(job_path, "wb") as f: f.write(job_file.read())
    with open(resume_path, "wb") as f: f.write(resume_file.read())

    job_text = DocumentReader(job_path).extract_text()
    resume_text = DocumentReader(resume_path).extract_text()

    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    job_title = extract_job_title(job_text)
    st.write(f"**–í–∞–∫–∞–Ω—Å–∏—è:** {job_title}")

    try:
        model_path = "model"  # –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        job_emb = get_embedding(job_text, model_path)
        resume_emb = get_embedding(resume_text, model_path)
        similarity = torch.mm(resume_emb, job_emb.T).item() * 100
        st.write(f"üîó –°—Ö–æ–∂–µ—Å—Ç—å —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏: **{similarity:.2f}%**")
        st.info(_generate_recommendation(similarity))
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}")

# === –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ª–æ–≥ ===
if similarity and similarity >= 85.5:
    st.success("‚úÖ –ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç! –ú–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ.")
    num_questions = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 3, 15, 30)

    if st.button("üöÄ –°—Ç–∞—Ä—Ç —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"):
        bot = InterviewBot(
            api_key=DEEPSEEK_API_KEY,
            job_description=job_text,
            resume=resume_text
        )
        st.session_state["bot"] = bot
        st.session_state["num_questions"] = num_questions
        st.session_state["dialog_active"] = True
        st.session_state["current_question"] = 0
        st.session_state["chat_log"] = []
        st.rerun()

if st.session_state.get("dialog_active"):
    bot = st.session_state["bot"]
    current_q = st.session_state["current_question"]

    # üî¥ –ö–Ω–æ–ø–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
    if st.button("üõë –ó–∞–∫–æ–Ω—á–∏—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ"):
        st.success("‚úÖ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º.")
        final_assessment = bot.generate_final_assessment()
        st.subheader("–ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞")
        st.write(final_assessment)
        bot.save_interview()

        # üìä –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞
        with st.sidebar.expander("üìä –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"):
            print_interview_summary(bot)

        st.session_state["dialog_active"] = False
        st.stop()

    if current_q < st.session_state["num_questions"]:
        prev_answer = bot.answers[-1] if bot.answers else None
        question = bot.generate_question(prev_answer)
        bot.questions.append(question)

        st.subheader(f"–í–æ–ø—Ä–æ—Å {current_q + 1}:")
        st.write(question)
        text_to_ogg(question)  # –æ–∑–≤—É—á–∏–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å

        # –∑–∞–ø–∏—Å—å –æ—Ç–≤–µ—Ç–∞ —Å—Ä–∞–∑—É
        st.write("üéôÔ∏è –ì–æ–≤–æ—Ä–∏—Ç–µ (25 —Å–µ–∫—É–Ω–¥)...")
        audio_file = load_audio(duration=25)
        answer = recognize_audio_whisper(audio_file)
        bot.answers.append(answer)

        feedback = bot.provide_feedback(question, answer)
        bot.feedbacks.append(feedback)

        st.session_state["chat_log"].append(
            {"question": question, "answer": answer, "feedback": feedback}
        )
        st.session_state["current_question"] += 1

        # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É
        time.sleep(2)
        st.rerun()
    else:
        st.success("üéØ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")
        final_assessment = bot.generate_final_assessment()
        st.subheader("–ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞")
        st.write(final_assessment)
        bot.save_interview()

        # üìä –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞
        with st.sidebar.expander("üìä –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"):
            print_interview_summary(bot)

        st.session_state["dialog_active"] = False

# === –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ ===
if "chat_log" in st.session_state and st.session_state["chat_log"]:
    st.sidebar.header("–ò—Å—Ç–æ—Ä–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é")
    for i, entry in enumerate(st.session_state["chat_log"], 1):
        st.sidebar.write(f"**–í–æ–ø—Ä–æ—Å {i}:** {entry['question']}")
        st.sidebar.write(f"üí¨ {entry['answer']}")
        st.sidebar.write(f"üìù {entry['feedback']}")
        st.sidebar.markdown("---")
